{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05fc2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import getopt\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "import cplex\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from ctypes import c_double\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e88e333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LapNoise():\n",
    "    a = random.uniform(0,1)\n",
    "    b = math.log(1/(1-a))\n",
    "    c = random.uniform(0,1)\n",
    "    if c>0.5:\n",
    "        return b\n",
    "    else:\n",
    "        return -b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79b52610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(cplex.callbacks.SimplexCallback):\n",
    "    def __call__(self):\n",
    "        value = self.get_objective_value()\n",
    "        if value < self.tar:\n",
    "            self.early_stop = True\n",
    "            self.abort()\n",
    "\n",
    "def ReadInput():\n",
    "    #Store the ids of entities\n",
    "    global entities\n",
    "    #The connections between entities and join results\n",
    "    global connections\n",
    "    #The DS\n",
    "    global downward_sensitivity\n",
    "    #The aggregation values of join results\n",
    "    global aggregation_values\n",
    "    #The real query result\n",
    "    global real_query_result\n",
    "    #The dictionary to store the tuples' sensitivities\n",
    "    entities_sensitivity_dic = {}\n",
    "    #The dictionary to re-id entities\n",
    "    id_dic = {}\n",
    "    #The number of base table tuples\n",
    "    id_num = 0\n",
    "    #Collect the DS\n",
    "    downward_sensitivity = 0\n",
    "    #The variable is repsented one entity\n",
    "    entities = []\n",
    "    connections = []\n",
    "    aggregation_values = []\n",
    "    #read input\n",
    "    #input_file_path = './network19_new.txt'\n",
    "    \n",
    "    input_file = open(input_file_path,'r')\n",
    "    for line in input_file.readlines():\n",
    "        elements = line.split()\n",
    "        connection = []\n",
    "        #The first value is the aggregation value\n",
    "        aggregation_value = float(elements[0])\n",
    "        #For each entity contribution to that join result\n",
    "        for element in elements[1:]:\n",
    "            element = int(element)\n",
    "            #Re-order the IDs\n",
    "            if element in id_dic.keys():\n",
    "                element = id_dic[element]\n",
    "            else:\n",
    "                entities.append(id_num)\n",
    "                id_dic[element] = id_num\n",
    "                element = id_num\n",
    "                id_num+=1\n",
    "            #Update the entity's sensitivity\n",
    "            if element in entities_sensitivity_dic.keys():\n",
    "                entities_sensitivity_dic[element]+=aggregation_value\n",
    "            else:\n",
    "                entities_sensitivity_dic[element]=aggregation_value\n",
    "            #Update the DS\n",
    "            if downward_sensitivity<=entities_sensitivity_dic[element]:\n",
    "                downward_sensitivity = entities_sensitivity_dic[element];                \n",
    "            connection.append(element)\n",
    "        connections.append(connection)\n",
    "        aggregation_values.append(aggregation_value)\n",
    "    real_query_result = sum(aggregation_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e39f72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.19526327e-04 3.19526327e-04 3.19526327e-04 ... 2.26737038e+00\n",
      " 2.29026527e+00 2.29344481e+00]\n",
      "97946\n",
      "1548.0\n",
      "794210.0\n"
     ]
    }
   ],
   "source": [
    "ReadInput()\n",
    "B = 1000000\n",
    "n = len(entities)\n",
    "num_user = n\n",
    "#eps of non-zero users\n",
    "eps = np.random.normal(1,0.3,int(n))\n",
    "eps[eps<1/(10*math.sqrt(n))]=1/(10*math.sqrt(n))\n",
    "# t = sum(eps)/n\n",
    "eps_sort = np.sort(eps)\n",
    "\n",
    "#to enable EM, we also need eps for zero users\n",
    "eps_zero = np.random.normal(1,0.3,num_user-int(n))\n",
    "eps_zero[eps_zero<1/(10*math.sqrt(n))]=1/(10*math.sqrt(n))\n",
    "eps_zero_sort = np.sort(eps_zero)\n",
    "\n",
    "t = (sum(eps)+sum(eps_zero))/num_user\n",
    "print(eps_sort)\n",
    "print(len(entities))\n",
    "print(downward_sensitivity)\n",
    "print(real_query_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f47f86f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LPSolver(tau, tar, LP_type = 1):\n",
    "    global entities\n",
    "    global connections\n",
    "    global approximate_factor\n",
    "    global stop_primals\n",
    "    global stop_duals\n",
    "    global global_max\n",
    "    global aggregation_values\n",
    "    global primals\n",
    "    global duals\n",
    "\n",
    "    num_constraints = len(entities)\n",
    "    num_variables = len(connections)\n",
    "    # Set the obj\n",
    "    cpx = cplex.Cplex()\n",
    "    cpx.objective.set_sense(cpx.objective.sense.maximize)\n",
    "    #Set variables\n",
    "    obj = np.ones(num_variables)\n",
    "    ub = np.zeros(num_variables)\n",
    "    for i in range(num_variables):\n",
    "        ub[i]=aggregation_values[i]\n",
    "    cpx.variables.add(obj=obj, ub=ub)\n",
    "    #Set the right hand side and the sign\n",
    "    rhs = tau\n",
    "    \n",
    "    senses = \"L\" * num_constraints\n",
    "    cpx.linear_constraints.add(rhs=rhs, senses=senses)\n",
    "    #Set the coefficients\n",
    "    cols = []\n",
    "    rows = []\n",
    "    vals = []\n",
    "    for i in range(num_variables):\n",
    "        for j in connections[i]:\n",
    "            cols.append(i)\n",
    "            rows.append(j)\n",
    "            vals.append(1)\n",
    "    cpx.linear_constraints.set_coefficients(zip(rows, cols, vals))\n",
    "    cpx.set_log_stream(None)\n",
    "    cpx.set_error_stream(None)\n",
    "    cpx.set_warning_stream(None)\n",
    "    cpx.set_results_stream(None) \n",
    "    #Set the optimizer\n",
    "    cpx.parameters.lpmethod.set(cpx.parameters.lpmethod.values.dual)\n",
    "\n",
    "    optimizer = cpx.register_callback(Optimizer)\n",
    "    optimizer.tar = tar\n",
    "    optimizer.early_stop = False\n",
    "    cpx.solve()\n",
    "#     print(optimizer.early_stop)\n",
    "    return cpx.solution.get_objective_value() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35801906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdp_query(eps,  n, eps_min, eps_max, beta, B):\n",
    "    start = time.time()\n",
    "\n",
    "    t = math.ceil(math.log(eps_max*B/eps_min, 2))\n",
    "    result=0\n",
    "    for k in range(t+1):\n",
    "        i = t+1-k\n",
    "        #ReadInput()\n",
    "#         print(\"i = \"+str(i))\n",
    "        if math.pow(2, i)*eps_min/eps_max>=downward_sensitivity:\n",
    "            sum_tilde = real_query_result+ t*math.pow(2, i)/eps_max*LapNoise()-t*math.pow(2, i)/eps_max*np.log(t/beta)\n",
    "        else:\n",
    "            tau = np.zeros(n)\n",
    "            for j in range(n):\n",
    "                tau[j] = math.floor(math.pow(2, i)*eps[j]/eps_max)\n",
    "\n",
    "            sum_tilde = LPSolver(tau, tar =result )+ t*math.pow(2, i)/eps_max*LapNoise()-t*math.pow(2, i)/eps_max*np.log(t/beta)\n",
    "#         print(result)\n",
    "        result = max(result,sum_tilde)\n",
    "    end= time.time()\n",
    "    \n",
    "    return result\n",
    "#     print(\"Time\")\n",
    "#     print(end-start)\n",
    "#     print(\"Noised Result\")\n",
    "#     print(result)\n",
    "#     print(\"relative error\")\n",
    "#     print(abs(result-real_query_result)/real_query_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdfb9826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result at scale = 0.125\n",
      "times\n",
      "[1.1485118865966797]\n",
      "errors\n",
      "[8746.061262208954]\n",
      "relative_error\n",
      "[0.2939259733233282]\n",
      "average times\n",
      "1.1485118865966797\n",
      "average errors\n",
      "8746.061262208954\n",
      "average relative_error\n",
      "0.2939259733233282\n",
      "result at scale = 0.25\n",
      "times\n",
      "[2.269239902496338]\n",
      "errors\n",
      "[10355.327586552841]\n",
      "relative_error\n",
      "[0.1725399068022867]\n",
      "average times\n",
      "2.269239902496338\n",
      "average errors\n",
      "10355.327586552841\n",
      "average relative_error\n",
      "0.1725399068022867\n",
      "result at scale = 0.5\n",
      "times\n",
      "[4.486430883407593]\n",
      "errors\n",
      "[14363.392050053531]\n",
      "relative_error\n",
      "[0.11943913493645718]\n",
      "average times\n",
      "4.486430883407593\n",
      "average errors\n",
      "14363.392050053531\n",
      "average relative_error\n",
      "0.11943913493645718\n"
     ]
    }
   ],
   "source": [
    "def main(argv):\n",
    "    #The input file including the relationships between aggregations and base tuples\n",
    "    global input_file_path\n",
    "    input_file_path = \"\"\n",
    "    #Privacy budget\n",
    "    global epsilon\n",
    "    epsilon = 0.1\n",
    "    #Error probablity: with probablity at least 1-beta, the error can be bounded\n",
    "    global beta\n",
    "    beta = 0.1\n",
    "    #The global sensitivity\n",
    "    global global_sensitivity\n",
    "    global_sensitivity = 1000000\n",
    "    #The number of processor\n",
    "    global processor_num\n",
    "    processor_num = 10\n",
    "    #The approximate factor\n",
    "    global approximate_factor\n",
    "    approximate_factor = 0\n",
    "    #The real query result\n",
    "    global real_query_result\n",
    "    \n",
    "    num_repeats = 1\n",
    "    \n",
    "    for i in range(3):\n",
    "        input_file_path = \"./Q5_\"+str(i)+\".txt\"\n",
    "        ReadInput()\n",
    "        times = []\n",
    "        errors = []\n",
    "        relative_error = []\n",
    "        real_results = []\n",
    "        \n",
    "        B = 1000000\n",
    "        n = len(entities)\n",
    "        num_user = int(160000*math.pow(2, i-3))\n",
    "        #eps of non-zero users\n",
    "        eps = np.random.normal(1,0.3,int(n))\n",
    "        eps[eps<1/(10*math.sqrt(num_user))]=1/(10*math.sqrt(num_user))\n",
    "        # t = sum(eps)/n\n",
    "        eps_sort = np.sort(eps)\n",
    "\n",
    "        eps_zero = np.random.normal(1,0.3,num_user-int(n))\n",
    "        eps_zero[eps_zero<1/(10*math.sqrt(num_user))]=1/(10*math.sqrt(num_user))\n",
    "        eps_zero_sort = np.sort(eps_zero)\n",
    "\n",
    "        t = (sum(eps)+sum(eps_zero))/num_user\n",
    "        eps_min = min(eps_sort[0], eps_zero_sort[0])\n",
    "        eps_max = max(eps_sort[n-1], eps_zero_sort[num_user-int(n)-1])\n",
    "        \n",
    "        for j in range(num_repeats):\n",
    "            start = time.time()\n",
    "            result = pdp_query(eps,  n, eps_min, eps_max, 0.1, B)\n",
    "            error = abs(result-real_query_result)\n",
    "            end= time.time()\n",
    "            times.append((end-start))\n",
    "            errors.append(error)\n",
    "            relative_error.append((error)/real_query_result)\n",
    "\n",
    "\n",
    "        print(\"result at scale = \"+str(math.pow(2, i-3)))\n",
    "        print(\"times\")\n",
    "        print(times)\n",
    "        print(\"errors\")\n",
    "        print(errors)\n",
    "        print(\"relative_error\")\n",
    "        print(relative_error)\n",
    "        print(\"average times\")\n",
    "        print(sum(times)/num_repeats)\n",
    "        print(\"average errors\")\n",
    "        print(sum(errors)/num_repeats)\n",
    "        print(\"average relative_error\")\n",
    "        print(sum(relative_error)/num_repeats)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acf53cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_pdp_query(eps,  n, beta, B):\n",
    "    start = time.time()\n",
    "\n",
    "    t = math.ceil(math.log(B, 2))\n",
    "    result=0\n",
    "    for i in range(t+1):\n",
    "#         ReadInput()\n",
    "        tau = np.ones(n)*math.pow(2,i)\n",
    "\n",
    "        sum_tilde = LPSolver(tau, tar =result )+ t*math.pow(2, i)/eps*LapNoise()-t*math.pow(2, i)/eps*np.log(t/beta)\n",
    "#         print(sum_tilde)\n",
    "        result = max(result,sum_tilde)\n",
    "    end= time.time()\n",
    "    \n",
    "    return result\n",
    "#     print(\"Time\")\n",
    "#     print(end-start)\n",
    "#     print(\"Noised Result\")\n",
    "#     print(result)\n",
    "#     print(\"relative error\")\n",
    "#     print(abs(result-real_query_result)/real_query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59096a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_pdp_query(eps_sort[0],  n,  0.1, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22b548fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample( t, B, beta):\n",
    "    \n",
    "    ReadInput()\n",
    "    start = time.time()\n",
    "    n = len(entities)\n",
    "    index = np.ones(n)\n",
    "\n",
    "    result=0\n",
    "    for i in range(n):\n",
    "        if eps[i]<t:\n",
    "            index[i] = np.random.binomial(1, (math.exp(eps[i])-1)/(math.exp(t)-1))\n",
    "            \n",
    "    for i in range(len(connections)):\n",
    "        for j in range(len(connections[0])):\n",
    "            if index[connections[i][j]]==0:\n",
    "                aggregation_values[i] = 0\n",
    "#     print(sum(aggregation_values))            \n",
    "    T = math.ceil(math.log(B, 2))\n",
    "    result=0\n",
    "    for i in range(T+1):\n",
    "        tau = np.ones(n)*math.pow(2,i)\n",
    "\n",
    "        sum_tilde = LPSolver(tau, tar =result )+ T*math.pow(2, i)/t*LapNoise()-T*math.pow(2, i)/t*np.log(T/beta)\n",
    "#         print(sum_tilde)\n",
    "        result = max(result,sum_tilde)            \n",
    "    end= time.time()\n",
    "    \n",
    "    return result, -start+end\n",
    "#     print(\"Time\")\n",
    "#     print(end-start)\n",
    "#     print(\"Noised Result\")\n",
    "#     print(result)\n",
    "#     print(\"relative error\")\n",
    "#     print(abs(result-real_query_result)/real_query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f2b25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464778.0\n",
      "Time\n",
      "2242.94388794899\n",
      "Noised Result\n",
      "411214.7399648202\n",
      "relative error\n",
      "0.4822342453950212\n"
     ]
    }
   ],
   "source": [
    "sample( t, B, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20482a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Read"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
